{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image-to-image","metadata":{}},{"cell_type":"markdown","source":"Image-to-image is similar to text-to-image, but in addition to a prompt, you can also pass an initial image as a starting point for the diffusion process. The initial image is encoded to latent space and noise is added to it. Then the latent diffusion model takes a prompt and the noisy latent image, predicts the added noise, and removes the predicted noise from the initial latent image to get the new latent image. Lastly, a decoder decodes the new latent image back into an image.","metadata":{}},{"cell_type":"markdown","source":"With ü§ó Diffusers, this is as easy as 1-2-3:","metadata":{}},{"cell_type":"markdown","source":"1.Load a checkpoint into the AutoPipelineForImage2Image class; this pipeline automatically handles loading the correct pipeline class based on the checkpoint:","metadata":{}},{"cell_type":"code","source":"!pip install diffusers==0.23.1","metadata":{"execution":{"iopub.status.busy":"2024-02-10T00:56:10.154027Z","iopub.execute_input":"2024-02-10T00:56:10.154463Z","iopub.status.idle":"2024-02-10T00:56:28.609287Z","shell.execute_reply.started":"2024-02-10T00:56:10.154432Z","shell.execute_reply":"2024-02-10T00:56:28.608178Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting diffusers==0.23.1\n  Downloading diffusers-0.23.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers==0.23.1) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers==0.23.1) (3.13.1)\nRequirement already satisfied: huggingface-hub>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.23.1) (0.20.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers==0.23.1) (6.11.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers==0.23.1) (1.24.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.23.1) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers==0.23.1) (2.31.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.23.1) (0.4.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.23.1) (2023.12.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.23.1) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.23.1) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.23.1) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.23.1) (21.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers==0.23.1) (3.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.23.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.23.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.23.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.23.1) (2023.11.17)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.13.2->diffusers==0.23.1) (3.1.1)\nDownloading diffusers-0.23.1-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: diffusers\nSuccessfully installed diffusers-0.23.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16, use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()","metadata":{"execution":{"iopub.status.busy":"2024-02-10T00:56:28.611168Z","iopub.execute_input":"2024-02-10T00:56:28.611571Z","iopub.status.idle":"2024-02-10T00:58:38.878595Z","shell.execute_reply.started":"2024-02-10T00:56:28.611517Z","shell.execute_reply":"2024-02-10T00:58:38.876653Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caeac951a82f4632bffecac1111de0f9"}},"metadata":{}},{"name":"stderr","text":"2024-02-10 00:56:34.116986: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-10 00:56:34.117166: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-10 00:56:34.292330: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/250 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"228145450b1c413ca82ccb14cda36bb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a98749546154e80aa14b1c0d70797f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/5.01G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d68a3d726f8448bdb2902c6f4b1e1399"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df1971cca5b743518b03f595a834c6da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/config.json:   0%|          | 0.00/1.67k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e6907607cbd4546abf0dc82ce584775"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"movq/config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59e14ece3b824ad4b5f53cc17da6a4e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/271M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0b551ba39094d2c8941f9d74791a2b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler/scheduler_config.json:   0%|          | 0.00/317 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae97e36e05a4b5687915add8459d9c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeaa9289727e40d685392dffc3b8e8ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/501 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b1a36f8d96644a6935d100c5fe955f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f432f3ee36284d5ca1ba7f4174b9e3f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"image_encoder/config.json:   0%|          | 0.00/2.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3ab4c5ec4e04a698fa8a0152e2b251f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"image_processor/preprocessor_config.json:   0%|          | 0.00/315 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe558d85c03d41bcb1995db7c1474bc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.69G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eac16e44a7646df9f6487102a11c6b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/config.json:   0%|          | 0.00/2.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fdf3037affd4a62a82d16e4df818639"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/4.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcc0a76b87934c57b89865981848926f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler/scheduler_config.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f6c3a5a8bbf4b54a01e05258c00e4a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"prior/config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de5b7368b73f41b4873c45ac5e949ff7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.78G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e1d70de3e594e648cf3adf8901447fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"637da168e6fd4265a6319104c415457d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47c95fb8d010499b8121818f4f87e24d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6104be9283dc4b6a98b7229eab21074b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/tokenizer_config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dd0e67830b3462fa66484648070dfea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36aaa4b49f64632b302c3013bb8d68b"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m pipeline\u001b[38;5;241m.\u001b[39menable_model_cpu_offload()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_xformers_memory_efficient_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py:406\u001b[0m, in \u001b[0;36mKandinskyV22Img2ImgCombinedPipeline.enable_xformers_memory_efficient_attention\u001b[0;34m(self, attention_op)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable_xformers_memory_efficient_attention\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_op: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_xformers_memory_efficient_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_op\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:1999\u001b[0m, in \u001b[0;36mDiffusionPipeline.enable_xformers_memory_efficient_attention\u001b[0;34m(self, attention_op)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable_xformers_memory_efficient_attention\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_op: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;124;03m    Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/). When this\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;124;03m    option is enabled, you should observe lower GPU memory usage and a potential speed up during inference. Speed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1999\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_use_memory_efficient_attention_xformers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_op\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:2025\u001b[0m, in \u001b[0;36mDiffusionPipeline.set_use_memory_efficient_attention_xformers\u001b[0;34m(self, valid, attention_op)\u001b[0m\n\u001b[1;32m   2022\u001b[0m modules \u001b[38;5;241m=\u001b[39m [m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m modules \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)]\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m-> 2025\u001b[0m     \u001b[43mfn_recursive_set_mem_eff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:2015\u001b[0m, in \u001b[0;36mDiffusionPipeline.set_use_memory_efficient_attention_xformers.<locals>.fn_recursive_set_mem_eff\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_recursive_set_mem_eff\u001b[39m(module: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_use_memory_efficient_attention_xformers\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2015\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_use_memory_efficient_attention_xformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_op\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m   2018\u001b[0m         fn_recursive_set_mem_eff(child)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:255\u001b[0m, in \u001b[0;36mModelMixin.set_use_memory_efficient_attention_xformers\u001b[0;34m(self, valid, attention_op)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m--> 255\u001b[0m         \u001b[43mfn_recursive_set_mem_eff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:251\u001b[0m, in \u001b[0;36mModelMixin.set_use_memory_efficient_attention_xformers.<locals>.fn_recursive_set_mem_eff\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    248\u001b[0m     module\u001b[38;5;241m.\u001b[39mset_use_memory_efficient_attention_xformers(valid, attention_op)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 251\u001b[0m     \u001b[43mfn_recursive_set_mem_eff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:251\u001b[0m, in \u001b[0;36mModelMixin.set_use_memory_efficient_attention_xformers.<locals>.fn_recursive_set_mem_eff\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    248\u001b[0m     module\u001b[38;5;241m.\u001b[39mset_use_memory_efficient_attention_xformers(valid, attention_op)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 251\u001b[0m     \u001b[43mfn_recursive_set_mem_eff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\n","    \u001b[0;31m[... skipping similar frames: ModelMixin.set_use_memory_efficient_attention_xformers.<locals>.fn_recursive_set_mem_eff at line 251 (1 times)]\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:251\u001b[0m, in \u001b[0;36mModelMixin.set_use_memory_efficient_attention_xformers.<locals>.fn_recursive_set_mem_eff\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    248\u001b[0m     module\u001b[38;5;241m.\u001b[39mset_use_memory_efficient_attention_xformers(valid, attention_op)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 251\u001b[0m     \u001b[43mfn_recursive_set_mem_eff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:248\u001b[0m, in \u001b[0;36mModelMixin.set_use_memory_efficient_attention_xformers.<locals>.fn_recursive_set_mem_eff\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_recursive_set_mem_eff\u001b[39m(module: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_use_memory_efficient_attention_xformers\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 248\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_use_memory_efficient_attention_xformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_op\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m    251\u001b[0m         fn_recursive_set_mem_eff(child)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/models/attention_processor.py:247\u001b[0m, in \u001b[0;36mAttention.set_use_memory_efficient_attention_xformers\u001b[0;34m(self, use_memory_efficient_attention_xformers, attention_op)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory efficient attention is currently not supported for LoRA or custom diffusion for attention processor type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m     )\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_xformers_available():\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m    248\u001b[0m         (\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRefer to https://github.com/facebookresearch/xformers for more information on how to install\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m xformers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m         ),\n\u001b[1;32m    252\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxformers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.cuda.is_available() should be True but is False. xformers\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m memory efficient attention is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m only available for GPU \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m     )\n","\u001b[0;31mModuleNotFoundError\u001b[0m: Refer to https://github.com/facebookresearch/xformers for more information on how to install xformers"],"ename":"ModuleNotFoundError","evalue":"Refer to https://github.com/facebookresearch/xformers for more information on how to install xformers","output_type":"error"}]},{"cell_type":"markdown","source":"We use enable_model_cpu_offload() and enable_xformers_memory_efficient_attention(), to save memory and increase inference speed. If you‚Äôre using PyTorch 2.0, then you don‚Äôt need to call enable_xformers_memory_efficient_attention() on your pipeline because it‚Äôll already be using PyTorch 2.0‚Äôs native scaled-dot product attention.","metadata":{}},{"cell_type":"markdown","source":"2.Load an image to pass to the pipeline:","metadata":{}},{"cell_type":"code","source":"init_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\")","metadata":{"execution":{"iopub.status.busy":"2024-02-10T00:58:38.880220Z","iopub.status.idle":"2024-02-10T00:58:38.881073Z","shell.execute_reply.started":"2024-02-10T00:58:38.880819Z","shell.execute_reply":"2024-02-10T00:58:38.880843Z"},"trusted":true},"execution_count":null,"outputs":[]}]}