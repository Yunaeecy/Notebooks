{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9681947,"sourceType":"datasetVersion","datasetId":5918106}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras \nfrom tqdm import tqdm\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom tensorflow.keras import regularizers\nfrom sklearn.metrics import confusion_matrix , accuracy_score, ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport glob \nimport pandas as pan\nimport matplotlib.pyplot as plotter\nimport math\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-11-05T10:18:41.792136Z","iopub.execute_input":"2024-11-05T10:18:41.792571Z","iopub.status.idle":"2024-11-05T10:19:01.168599Z","shell.execute_reply.started":"2024-11-05T10:18:41.792528Z","shell.execute_reply":"2024-11-05T10:19:01.167337Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create train Files_Name\nimage_data='/kaggle/input/chest-x-ray-dataset-4-categories/Chest X_Ray Dataset'\ntrain_files = [i for i in glob.glob(image_data + \"//*//*\")]\nnp.random.shuffle(train_files)\ntrain_labels = [os.path.dirname(i).split(\"/\")[-1] for i in train_files]\ntrain_data = zip(train_files, train_labels)\ntrain_df = pd.DataFrame(train_data, columns=[\"Image\", \"Label\"])\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2024-11-05T10:19:01.170447Z","iopub.execute_input":"2024-11-05T10:19:01.171374Z","iopub.status.idle":"2024-11-05T10:19:02.975141Z","shell.execute_reply.started":"2024-11-05T10:19:01.171324Z","shell.execute_reply":"2024-11-05T10:19:02.973843Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set a theme for better aesthetics\nsns.set_theme(style=\"whitegrid\")\n\n# Calculate counts and percentages for each label\ncount_data = train_df[\"Label\"].value_counts()\npercentage_data = train_df[\"Label\"].value_counts(normalize=True) * 100  # Calculate percentage\n\n# Print percentage for each label (optional)\nprint(percentage_data)\n\n# Sort the labels based on count values in descending order\nsorted_data = count_data.sort_values(ascending=False).index\n\n# Create a color palette for the bars\npalette = sns.color_palette(\"pastel\", len(sorted_data))\n\n# Plot the count plot with sorted labels\nplt.figure(figsize=(12, 6))\nax = sns.countplot(x=train_df[\"Label\"], order=sorted_data, palette=palette)\n\n# Annotate each bar with the percentage value\nfor p in ax.patches:\n    height = p.get_height()  # Get the height of the bar\n    percentage = f'{(height / count_data.sum()) * 100:.2f}%'  # Calculate percentage\n    ax.annotate(percentage,  # The label to be annotated\n                (p.get_x() + p.get_width() / 2., height),  # Position of the label\n                ha='center', va='bottom', fontsize=10, color='black', xytext=(0, 8), textcoords='offset points')\n\n# Rotate x-axis labels for better visibility and set the label font size\nplt.xticks(rotation=0, ha='right', fontsize=12)\n\n# Add title and labels with improved fonts and padding\nplt.title(\"Label Distribution with Percentages\", fontsize=16, pad=20)\nplt.xlabel(\"Labels\", fontsize=14, labelpad=10)\nplt.ylabel(\"Count\", fontsize=14, labelpad=10)\n\n# Remove the top and right spines for a cleaner look\nsns.despine()\n\n# Show the plot\nplt.tight_layout()  # Adjust layout to prevent overlap\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-05T10:19:02.978272Z","iopub.execute_input":"2024-11-05T10:19:02.978848Z","iopub.status.idle":"2024-11-05T10:19:03.544698Z","shell.execute_reply.started":"2024-11-05T10:19:02.978788Z","shell.execute_reply":"2024-11-05T10:19:03.543211Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Preprocessing\n\nkeras.preprocessing\n\ndirectory : Directory where the data is located. If labels is \"inferred\", it should contain subdirectories, each containing images for a class. Otherwise, the directory structure is ignored.\n\nbatch_size : Size of the batches of data. If None, the data will not be batched (the dataset will yield individual samples). Defaults to 32.\n\nimage_size : Size to resize images to after they are read from disk, specified as (height, width). Since the pipeline processes batches of images that must all have the same size, this must be provided.\n\nseed : Optional random seed for shuffling and transformations.\n\nvalidation_split : Optional float between 0 and 1, fraction of data to reserve for validation.\n\nsubset : Subset of the data to return. One of \"training\", \"validation\", or \"both\". Only used if validation_split is set. When subset=\"both\", the utility returns a tuple of two datasets (the training and validation datasets respectively).\n\n\n\n#### Split the data into train, validation, and test sets","metadata":{}},{"cell_type":"code","source":"# Set up variables\n\ntrain_data_dir = image_data\nbatch_size = 8\ntarget_size = (224, 224)\nvalidation_split = 0.25  # Total split for validation + test\nseed = 100\n\n# Generate training + validation dataset\ntrain = tf.keras.preprocessing.image_dataset_from_directory(\n    train_data_dir,\n    validation_split=validation_split,\n    subset=\"training\",\n    seed=seed,\n    image_size=target_size,\n    batch_size=batch_size,\n)\n\n# Generate validation + test dataset\nval_test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    train_data_dir,\n    validation_split=validation_split,\n    subset=\"validation\",\n    seed=seed,\n    image_size=target_size,\n    batch_size=batch_size,\n)\n\n# Calculate test dataset size (assuming a split of 80% train, 10% validation, and 10% test)\nval_size = math.floor(len(val_test_dataset) * 0.5)\ntest_size = len(val_test_dataset) - val_size\n\n# Further split into validation and test datasets\nvalidation = val_test_dataset.take(val_size)\ntest = val_test_dataset.skip(val_size)\n\n# Check the sample count for each dataset\nprint(f\"Training samples: {len(train)}, Validation samples: {val_size}, Test samples: {test_size}\")\n\n# Sample counts for each dataset\ntrain_samples = len(train)\nval_samples = val_size\ntest_samples = test_size\n\n# Names for the datasets\ndatasets = ['Training', 'Validation', 'Test']\nsample_counts = [train_samples, val_samples, test_samples]\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.bar(datasets, sample_counts, color=['blue', 'orange', 'green'])\nplt.xlabel('Dataset', fontsize=14)\nplt.ylabel('Number of Samples', fontsize=14)\nplt.title('Sample Distribution in Datasets', fontsize=16)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.ylim(0, max(sample_counts) + 100)  \nplt.grid(axis='y')\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:19:03.546791Z","iopub.execute_input":"2024-11-05T10:19:03.547291Z","iopub.status.idle":"2024-11-05T10:19:21.028293Z","shell.execute_reply.started":"2024-11-05T10:19:03.547238Z","shell.execute_reply":"2024-11-05T10:19:21.027053Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Split 75% for training, 12.5% for validation, and 12.5% for test.","metadata":{}},{"cell_type":"code","source":"class_names = train.class_names\n\nplt.figure(figsize=(15, 20))\nnum_images_per_class = 2 \ncount = {class_name: 0 for class_name in class_names}  \n\nfor images, labels in train.take(1):\n    for i in range(len(labels)):\n        label = class_names[labels[i]]\n        if count[label] < num_images_per_class:  \n            ax = plt.subplot(8, 4, sum(count.values()) + 1)  \n            plt.imshow(images[i].numpy().astype(\"uint8\"))\n            plt.title(label)\n            plt.axis(\"off\")\n            count[label] += 1  \n        if sum(count.values()) >= num_images_per_class * len(class_names):\n            break  #","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:19:21.030063Z","iopub.execute_input":"2024-11-05T10:19:21.030474Z","iopub.status.idle":"2024-11-05T10:19:22.222071Z","shell.execute_reply.started":"2024-11-05T10:19:21.030432Z","shell.execute_reply":"2024-11-05T10:19:22.220842Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modeling\n\nAbout setting\n\ninput_shape : Optional shape tuple, to be specified if you would like to use a model with an input image resolution that is not (224, 224, 3). It should have exactly 3 inputs channels (224, 224, 3). You can also omit this option if you would like to infer input_shape from an input_tensor. If you choose to include both input_tensor and input_shape then input_shape will be used if they match, if the shapes do not match then we will throw an error. E.g. (160, 160, 3) would be one valid value.\ninclude_top : Boolean, whether to include the fully-connected layer at the top of the network. Defaults to True.\n\nweights : String, one of None (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.\n\n\nThe training accuracy lags behind the validation accuracy, it might indicate underfitting, or that the model isn't learning the training data well enough. Here are some strategies to improve the training accuracy\n\n1.Load the Base Model\n\n2.Freeze the Base Model\n\n3.Create the Keras Model , and add the Base Model\n\n4.Add Global Average Pooling Layer\n\n5.Add Dense Layer with L2 Regularization\n\n6.Add Batch Normalization , and Activation Layer\n\n7.Add Dropout Layer(0.5)\n","metadata":{}},{"cell_type":"code","source":"# Load the base model\nbase_model = tf.keras.applications.ConvNeXtTiny(input_shape=(224, 224, 3),include_top=False,weights='imagenet')\n\n# Freeze the base model\nfor layer in base_model.layers[-20:]:  \n    layer.trainable = True\n\n# Create the Keras model\nkeras_model = keras.models.Sequential()\nkeras_model.add(base_model)\nkeras_model.add(keras.layers.GlobalAveragePooling2D())\nkeras_model.add(keras.layers.Dense(256, activation=None, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\nkeras_model.add(keras.layers.BatchNormalization())\nkeras_model.add(keras.layers.Activation('relu'))\nkeras_model.add(keras.layers.Dropout(0.5))\nkeras_model.add(keras.layers.Dense(4,activation=tf.nn.softmax))\nkeras_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:19:22.223709Z","iopub.execute_input":"2024-11-05T10:19:22.224157Z","iopub.status.idle":"2024-11-05T10:19:27.454717Z","shell.execute_reply.started":"2024-11-05T10:19:22.224115Z","shell.execute_reply":"2024-11-05T10:19:27.453461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model with an optimizer and learning rate\noptimizer = keras.optimizers.Adam(learning_rate=1e-5)\nkeras_model.compile(optimizer=optimizer,\n                    loss='sparse_categorical_crossentropy',  \n                    metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:19:27.456327Z","iopub.execute_input":"2024-11-05T10:19:27.456901Z","iopub.status.idle":"2024-11-05T10:19:27.476108Z","shell.execute_reply.started":"2024-11-05T10:19:27.456794Z","shell.execute_reply":"2024-11-05T10:19:27.474816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"keras_model.build(input_shape=(None, 224, 224, 3))\ndummy_input = tf.random.normal((1, 224, 224, 3))\nkeras_model(dummy_input)\ntf.keras.utils.plot_model(keras_model, to_file='model.png', show_shapes=True, show_layer_names=True, show_dtype=True, dpi=80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:19:27.479893Z","iopub.execute_input":"2024-11-05T10:19:27.480363Z","iopub.status.idle":"2024-11-05T10:19:30.178733Z","shell.execute_reply.started":"2024-11-05T10:19:27.480317Z","shell.execute_reply":"2024-11-05T10:19:30.177136Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Credit:\n\n\nhttps://www.kaggle.com/code/guanlintao/acc-98-convnexttiny-chest-x-ray/notebook","metadata":{}}]}